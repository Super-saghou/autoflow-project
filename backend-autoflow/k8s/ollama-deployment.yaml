apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-deployment
  labels:
    app: ollama
    component: ai-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
        component: ai-inference
    spec:
      containers:
        - name: ollama
          image: sarra539/autoflow-ollama:latest
          imagePullPolicy: Always
          ports:
            - containerPort: 11434
              name: ollama-api
              protocol: TCP
          env:
            - name: OLLAMA_HOST
              value: "0.0.0.0"
            - name: OLLAMA_ORIGINS
              value: "*"
          resources:
            requests:
              memory: "4Gi"
              cpu: "1000m"
            limits:
              memory: "8Gi"
              cpu: "2000m"
          volumeMounts:
            - name: ollama-models
              mountPath: /root/.ollama
          startupProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 120
            periodSeconds: 30
            failureThreshold: 10
            timeoutSeconds: 10
          livenessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 180
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          lifecycle:
            postStart:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |
                    echo "Waiting for Ollama to start..."
                    sleep 20
                    echo "Downloading llama3.2:1b model..."
                    ollama pull llama3.2:1b
                    echo "Model download completed"
      volumes:
        - name: ollama-models
          persistentVolumeClaim:
            claimName: ollama-models-pvc
      restartPolicy: Always 